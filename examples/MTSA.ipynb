{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diegompin/mtsa/blob/feature%2Fv0.0.8/examples/MTSA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "T3S9SKUv2m_f"
      },
      "source": [
        "# MTSA - **M**ultiple **T**ime **S**eries **A**nalysis\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BkjlJ89P5Ftn"
      },
      "source": [
        "### Installing MTSA module:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ko7L-5oj2-J4"
      },
      "outputs": [],
      "source": [
        "#!pip install mtsa"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WJOI-F8i5Ohp"
      },
      "source": [
        "### Cloning MTSA repository:"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "teEVpIfJ5cB-"
      },
      "source": [
        "*Obs: This step is necessary to access the example data.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7plkqXx3fFM"
      },
      "outputs": [],
      "source": [
        "#!git clone https://github.com/diegompin/mtsa.git"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GPQ09fBr5ue_"
      },
      "source": [
        "### Setting data directory:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "fDEi8QAf3Wq0",
        "outputId": "f8d21c19-110b-4ac4-d762-f6040379112d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "path_input_1 = os.path.join(os.getcwd(),  \"sample_data\", \"machine_type_1\", \"id_00\")\n",
        "path_input_2 = os.path.join(os.getcwd(),  \"mtsa\", \"examples\", \"sample_data\", \"machine_type_1\", \"id_00\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-04-02 22:25:41.915871: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-04-02 22:25:42.521631: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
            "2024-04-02 22:25:42.521673: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
            "2024-04-02 22:25:42.521680: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import tensorflow as tf\n",
        "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "assert len(gpus) > 0, \"Not enough GPU hardware devices available\"\n",
        "if gpus:\n",
        "    for gpu in gpus:\n",
        "        tf.config.experimental.set_memory_growth(gpu, True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"..\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8sgHTpcy53JY"
      },
      "source": [
        "### Reading Data Files:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "uoRf7Uzl24L9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
          ]
        }
      ],
      "source": [
        "from mtsa import calculate_aucroc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyZ2hEM228t3",
        "outputId": "b907463f-efe2-419a-ebbb-f87b8851acd0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1., 1., 1., 1., 1.])"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "from mtsa import files_train_test_split\n",
        "#path_input_1 = '/data/MIMII/fan/id_00/'\n",
        "X_train, X_test, y_train, y_test = files_train_test_split(path_input_1)\n",
        "if(len(y_train) == 0): \n",
        "    X_train, X_test, y_train, y_test = files_train_test_split(path_input_2)\n",
        "y_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### GANF\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "from mtsa.models.ganf import GANF\n",
        "\n",
        "model_GANF = GANF()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/data/cristofer/mtsa/examples/../mtsa/models/ganf.py:210: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  return torch.tensor(init, requires_grad=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch 0 of 5\n",
            "epoch 1 of 5\n"
          ]
        }
      ],
      "source": [
        "model_GANF.fit(X_train, y_train)\n",
        "model_GANF.model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.76"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "auc = calculate_aucroc(model_GANF, X_test, y_test)\n",
        "auc"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GUzDG1sW6LNf"
      },
      "source": [
        "### MFFCMix Model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "ztsT35vW4ER7",
        "outputId": "70427501-5395-4950-c9ac-b5dedb81a601"
      },
      "outputs": [],
      "source": [
        "from mtsa import MFCCMix\n",
        "model_mfccmix = MFCCMix()\n",
        "model_mfccmix.fit(X_train, y_train)\n",
        "model_mfccmix.model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRE7dHnc4TQ6",
        "outputId": "4f7d2865-4c63-442d-c939-d2dc50167958"
      },
      "outputs": [],
      "source": [
        "auc = calculate_aucroc(model_mfccmix, X_test, y_test)\n",
        "auc"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-zkELfEF6Sjh"
      },
      "source": [
        "### Hitachi Model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "liN9NNJA4fCN",
        "outputId": "557e8065-66bb-43f6-adab-ac3e51fa8f4f"
      },
      "outputs": [],
      "source": [
        "from mtsa import Hitachi\n",
        "model_hitachi = Hitachi()\n",
        "model_hitachi.fit(X_train, y_train)\n",
        "model_hitachi.model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmdbBjP04lI1",
        "outputId": "f2fd5bd8-4144-4a4d-f51a-47d173ebc56c"
      },
      "outputs": [],
      "source": [
        "auc = calculate_aucroc(model_hitachi, X_test, y_test)\n",
        "auc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RQ2nso5T4rag"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNBZGR2CHjd5DTVJQyBRUus",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
