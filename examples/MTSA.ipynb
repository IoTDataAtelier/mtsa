{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diegompin/mtsa/blob/feature%2Fv0.0.8/examples/MTSA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "T3S9SKUv2m_f"
      },
      "source": [
        "# MTSA - **M**ultiple **T**ime **S**eries **A**nalysis\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BkjlJ89P5Ftn"
      },
      "source": [
        "### Installing MTSA module:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ko7L-5oj2-J4"
      },
      "outputs": [],
      "source": [
        "!pip install mtsa"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "WJOI-F8i5Ohp"
      },
      "source": [
        "### Cloning MTSA repository:"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "teEVpIfJ5cB-"
      },
      "source": [
        "*Obs: This step is necessary to access the example data.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7plkqXx3fFM"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/diegompin/mtsa.git"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GPQ09fBr5ue_"
      },
      "source": [
        "### Setting data directory:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "fDEi8QAf3Wq0",
        "outputId": "f8d21c19-110b-4ac4-d762-f6040379112d"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "path_input_1 = os.path.join(os.getcwd(),  \"sample_data\", \"machine_type_1\", \"id_00\")\n",
        "path_input_2 = os.path.join(os.getcwd(),  \"mtsa\", \"examples\", \"sample_data\", \"machine_type_1\", \"id_00\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-03-26 21:55:43.148277: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-03-26 21:55:43.758453: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
            "2024-03-26 21:55:43.758496: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
            "2024-03-26 21:55:43.758502: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
        "assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
        "config = tf.config.experimental.set_memory_growth(physical_devices[0], True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "sys.path.append(\"..\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "8sgHTpcy53JY"
      },
      "source": [
        "### Reading Data Files:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uoRf7Uzl24L9"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-03-26 21:55:57.029405: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-03-26 21:55:57.612061: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
            "2024-03-26 21:55:57.612103: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
            "2024-03-26 21:55:57.612108: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
          ]
        }
      ],
      "source": [
        "from mtsa import calculate_aucroc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyZ2hEM228t3",
        "outputId": "b907463f-efe2-419a-ebbb-f87b8851acd0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([1., 1., 1., 1., 1.])"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "from mtsa import files_train_test_split\n",
        "X_train, X_test, y_train, y_test = files_train_test_split(path_input_1)\n",
        "if(len(y_train) == 0): \n",
        "    X_train, X_test, y_train, y_test = files_train_test_split(path_input_2)\n",
        "y_train"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "GUzDG1sW6LNf"
      },
      "source": [
        "### MFFCMix Model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "ztsT35vW4ER7",
        "outputId": "70427501-5395-4950-c9ac-b5dedb81a601"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;wav2array&#x27;, Wav2Array()),\n",
              "                (&#x27;array2mfcc&#x27;, Array2Mfcc(sampling_rate=None)),\n",
              "                (&#x27;features&#x27;,\n",
              "                 FeatureUnion(transformer_list=[(&#x27;M&#x27;,\n",
              "                                                 MagnitudeMeanFeatureMfcc()),\n",
              "                                                (&#x27;S&#x27;,\n",
              "                                                 MagnitudeStdFeatureMfcc()),\n",
              "                                                (&#x27;C&#x27;,\n",
              "                                                 CorrelationFeatureMfcc())])),\n",
              "                (&#x27;final_model&#x27;, GaussianMixture())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;wav2array&#x27;, Wav2Array()),\n",
              "                (&#x27;array2mfcc&#x27;, Array2Mfcc(sampling_rate=None)),\n",
              "                (&#x27;features&#x27;,\n",
              "                 FeatureUnion(transformer_list=[(&#x27;M&#x27;,\n",
              "                                                 MagnitudeMeanFeatureMfcc()),\n",
              "                                                (&#x27;S&#x27;,\n",
              "                                                 MagnitudeStdFeatureMfcc()),\n",
              "                                                (&#x27;C&#x27;,\n",
              "                                                 CorrelationFeatureMfcc())])),\n",
              "                (&#x27;final_model&#x27;, GaussianMixture())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Wav2Array</label><div class=\"sk-toggleable__content\"><pre>Wav2Array()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Array2Mfcc</label><div class=\"sk-toggleable__content\"><pre>Array2Mfcc(sampling_rate=None)</pre></div></div></div><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">features: FeatureUnion</label><div class=\"sk-toggleable__content\"><pre>FeatureUnion(transformer_list=[(&#x27;M&#x27;, MagnitudeMeanFeatureMfcc()),\n",
              "                               (&#x27;S&#x27;, MagnitudeStdFeatureMfcc()),\n",
              "                               (&#x27;C&#x27;, CorrelationFeatureMfcc())])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>M</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MagnitudeMeanFeatureMfcc</label><div class=\"sk-toggleable__content\"><pre>MagnitudeMeanFeatureMfcc()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>S</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MagnitudeStdFeatureMfcc</label><div class=\"sk-toggleable__content\"><pre>MagnitudeStdFeatureMfcc()</pre></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><label>C</label></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CorrelationFeatureMfcc</label><div class=\"sk-toggleable__content\"><pre>CorrelationFeatureMfcc()</pre></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GaussianMixture</label><div class=\"sk-toggleable__content\"><pre>GaussianMixture()</pre></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(steps=[('wav2array', Wav2Array()),\n",
              "                ('array2mfcc', Array2Mfcc(sampling_rate=None)),\n",
              "                ('features',\n",
              "                 FeatureUnion(transformer_list=[('M',\n",
              "                                                 MagnitudeMeanFeatureMfcc()),\n",
              "                                                ('S',\n",
              "                                                 MagnitudeStdFeatureMfcc()),\n",
              "                                                ('C',\n",
              "                                                 CorrelationFeatureMfcc())])),\n",
              "                ('final_model', GaussianMixture())])"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from mtsa import MFCCMix\n",
        "model_mfccmix = MFCCMix()\n",
        "model_mfccmix.fit(X_train, y_train)\n",
        "model_mfccmix.model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRE7dHnc4TQ6",
        "outputId": "4f7d2865-4c63-442d-c939-d2dc50167958"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.92"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "auc = calculate_aucroc(model_mfccmix, X_test, y_test)\n",
        "auc"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "-zkELfEF6Sjh"
      },
      "source": [
        "### Hitachi Model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "liN9NNJA4fCN",
        "outputId": "557e8065-66bb-43f6-adab-ac3e51fa8f4f"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;wav2array&#x27;, Wav2Array(mono=False)),\n",
              "                (&#x27;demux2array&#x27;, Demux2Array()),\n",
              "                (&#x27;array2melspec&#x27;,\n",
              "                 Array2MelSpec(frames=5, hop_length=512, n_fft=1024, n_mels=64,\n",
              "                               power=2.0, sampling_rate=None)),\n",
              "                (&#x27;final_model&#x27;,\n",
              "                 &lt;mtsa.models.hitachi.AutoEncoderMixin object at 0x7f66601473a0&gt;)])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;wav2array&#x27;, Wav2Array(mono=False)),\n",
              "                (&#x27;demux2array&#x27;, Demux2Array()),\n",
              "                (&#x27;array2melspec&#x27;,\n",
              "                 Array2MelSpec(frames=5, hop_length=512, n_fft=1024, n_mels=64,\n",
              "                               power=2.0, sampling_rate=None)),\n",
              "                (&#x27;final_model&#x27;,\n",
              "                 &lt;mtsa.models.hitachi.AutoEncoderMixin object at 0x7f66601473a0&gt;)])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" ><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Wav2Array</label><div class=\"sk-toggleable__content\"><pre>Wav2Array(mono=False)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Demux2Array</label><div class=\"sk-toggleable__content\"><pre>Demux2Array()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Array2MelSpec</label><div class=\"sk-toggleable__content\"><pre>Array2MelSpec(frames=5, hop_length=512, n_fft=1024, n_mels=64, power=2.0,\n",
              "              sampling_rate=None)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AutoEncoderMixin</label><div class=\"sk-toggleable__content\"><pre>&lt;mtsa.models.hitachi.AutoEncoderMixin object at 0x7f66601473a0&gt;</pre></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "Pipeline(steps=[('wav2array', Wav2Array(mono=False)),\n",
              "                ('demux2array', Demux2Array()),\n",
              "                ('array2melspec',\n",
              "                 Array2MelSpec(frames=5, hop_length=512, n_fft=1024, n_mels=64,\n",
              "                               power=2.0, sampling_rate=None)),\n",
              "                ('final_model',\n",
              "                 <mtsa.models.hitachi.AutoEncoderMixin object at 0x7f66601473a0>)])"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from mtsa import Hitachi\n",
        "model_hitachi = Hitachi()\n",
        "model_hitachi.fit(X_train, y_train)\n",
        "model_hitachi.model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmdbBjP04lI1",
        "outputId": "f2fd5bd8-4144-4a4d-f51a-47d173ebc56c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "14/14 [==============================] - 0s 17ms/step\n",
            "14/14 [==============================] - 0s 843us/step\n",
            "14/14 [==============================] - 0s 1ms/step\n",
            "14/14 [==============================] - 0s 730us/step\n",
            "14/14 [==============================] - 0s 925us/step\n",
            "14/14 [==============================] - 0s 1ms/step\n",
            "14/14 [==============================] - 0s 892us/step\n",
            "14/14 [==============================] - 0s 910us/step\n",
            "14/14 [==============================] - 0s 884us/step\n",
            "14/14 [==============================] - 0s 1ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.24"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "auc = calculate_aucroc(model_hitachi, X_test, y_test)\n",
        "auc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### RANSynCoders"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Data preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(220500, 5)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from mtsa import Wav2Array\n",
        "\n",
        "wav_to_array = Wav2Array(mono=False)\n",
        "input_vector = wav_to_array.transform(X_train)\n",
        "input_vector_transpose = input_vector.transpose()\n",
        "input_vector_transpose.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.00000e+00],\n",
              "       [1.00000e+00],\n",
              "       [2.00000e+00],\n",
              "       ...,\n",
              "       [2.20497e+05],\n",
              "       [2.20498e+05],\n",
              "       [2.20499e+05]], dtype=float32)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "indices_linha = np.arange(len(input_vector_transpose), dtype=np.float32).reshape(-1, 1)\n",
        "indices_linha"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00, 0.00000e+00],\n",
              "       [1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00, 1.00000e+00],\n",
              "       [2.00000e+00, 2.00000e+00, 2.00000e+00, 2.00000e+00, 2.00000e+00],\n",
              "       ...,\n",
              "       [2.20497e+05, 2.20497e+05, 2.20497e+05, 2.20497e+05, 2.20497e+05],\n",
              "       [2.20498e+05, 2.20498e+05, 2.20498e+05, 2.20498e+05, 2.20498e+05],\n",
              "       [2.20499e+05, 2.20499e+05, 2.20499e+05, 2.20499e+05, 2.20499e+05]],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "T_train = np.tile(indices_linha, (1, input_vector_transpose.shape[1]))\n",
        "T_train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Normalization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0.45243862, 0.45697623, 0.4641472 , 0.47902727, 0.41379306],\n",
              "       [0.4572944 , 0.45485774, 0.4669805 , 0.46893227, 0.3899437 ],\n",
              "       [0.4674927 , 0.45469445, 0.45470366, 0.45873913, 0.402269  ],\n",
              "       ...,\n",
              "       [0.51886237, 0.4709344 , 0.43578866, 0.44792703, 0.43859902],\n",
              "       [0.5289    , 0.48571432, 0.42856482, 0.4473591 , 0.43954355],\n",
              "       [0.50717294, 0.47945595, 0.43226197, 0.45647883, 0.4483705 ]],\n",
              "      dtype=float32)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "xscaler = MinMaxScaler()\n",
        "x_train_scaled = xscaler.fit_transform(input_vector_transpose)\n",
        "x_train_scaled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "N = 10  #5 * round((input_vector_transpose.shape[1] / 3) / 5)  # 10 for both bootstrap sample size and number of estimators\n",
        "encoder_layers = 1  # number of hidden layers for each encoder\n",
        "decoder_layers = 2  # number of hidden layers for each decoder\n",
        "z = int((N / 2) - 1)  # size of latent space\n",
        "activation = 'relu'\n",
        "output_activation = 'sigmoid'\n",
        "S = 5  # Number of frequency components to fit to input signals\n",
        "delta = 0.05\n",
        "batch_size = 180\n",
        "freq_warmup = 5  # pre-training epochs\n",
        "sin_warmup = 5  # synchronization pre-training\n",
        "epochs = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "RQ2nso5T4rag"
      },
      "outputs": [],
      "source": [
        "from mtsa import RANSynCoders\n",
        "\n",
        "model = RANSynCoders(\n",
        "    n_estimators=N, \n",
        "    max_features=4, \n",
        "    encoding_depth=encoder_layers, \n",
        "    latent_dim=z, \n",
        "    decoding_depth=decoder_layers, \n",
        "    activation=activation,\n",
        "    output_activation=output_activation,\n",
        "    delta=delta,\n",
        "    synchronize=False,\n",
        "    max_freqs=S,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Start of epoch 0\n",
            "upper_bound_loss: 0.0034623307 lower_bound_loss: 0.0037433212\n",
            "Start of epoch 1\n",
            "upper_bound_loss: 0.003682908 lower_bound_loss: 0.0034295316\n",
            "Start of epoch 2\n",
            "upper_bound_loss: 0.0031617347 lower_bound_loss: 0.0035936886\n",
            "Start of epoch 3\n",
            "upper_bound_loss: 0.0032379045 lower_bound_loss: 0.0034493578\n",
            "Start of epoch 4\n",
            "upper_bound_loss: 0.0034687198 lower_bound_loss: 0.003272461\n",
            "Start of epoch 5\n",
            "upper_bound_loss: 0.0034595944 lower_bound_loss: 0.0031903828\n",
            "Start of epoch 6\n",
            "upper_bound_loss: 0.0032685772 lower_bound_loss: 0.0029391362\n",
            "Start of epoch 7\n",
            "upper_bound_loss: 0.0038495008 lower_bound_loss: 0.0035384526\n",
            "Start of epoch 8\n",
            "upper_bound_loss: 0.0032675646 lower_bound_loss: 0.0034743175\n",
            "Start of epoch 9\n",
            "upper_bound_loss: 0.0035875158 lower_bound_loss: 0.0032549233\r"
          ]
        }
      ],
      "source": [
        "model.fit(x_train_scaled, T_train, epochs=epochs, batch_size=batch_size, freq_warmup=freq_warmup, sin_warmup=sin_warmup)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNBZGR2CHjd5DTVJQyBRUus",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
